---
title: "Semana 1 – RAG y la matemática de la semántica"
date: 2025-08-13
tags: [ai, aprendizaje, diario, rag, ollama]
summary: "Descubriendo RAG: cómo funciona, por qué es hermoso y qué pasos seguimos para hacerlo andar."
---

Esta semana aprendí qué es RAG, cómo funciona y para qué sirve. Una vez que lo entendí, se me ocurrieron al menos diez aplicaciones para hacer.
También me pareció transparente y bello el concepto: que exista una matemática de la semántica. Hermoso.

- Instalamos Ollama (mi GPT y yo, claro).
- Elegimos un modelo.
- Con Ollama prendido, ya tenemos la parte del LLM funcionando.
- En otra cacerola (nosotros usamos Python), seguimos estos pasos:
  - Tomamos una serie de documentos (por ahora cadenas de texto) y se las pasamos al LLM para que las **embeba**. Por cada documento, nos devuelve un vector.
  - Hacemos una pregunta, relativa a los documentos, y también se la pasamos al LLM para que la embeba (y obtenemos el vector de la pregunta).
  - Luego, usando una función matemática, comparamos los vectores y buscamos qué documentos están próximos (es decir, son semánticamente parecidos) a la pregunta. Esto nos devuelve el contexto adecuado (o circunscripto matemáticamente) a nuestra pregunta.
  - Ese contexto y la pregunta original los usamos con otra función del LLM, que es la que… contesta preguntas.
    Si todo salió bien, debería darnos una respuesta acorde a los documentos que le dimos.

---

**Notas al margen:**

- **Ollama**, porque en estos primeros intentos prefiero no gastar dinero (porque, no se confundan como yo, pagar por ChatGPT no te da una API Key).
- **Lenguaje coloquial y falta de elementos técnicos:** porque prefiero compartir y consolidar el proceso, no las herramientas o técnicas. Pero sí les digo que uso ChatGPT y Cursor (las suscripciones baratas). Cada tanto tanteo las webs de Claude o DeepSeek.
- **El humor:** bien, gracias.
